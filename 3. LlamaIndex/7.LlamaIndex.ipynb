{"cells":[{"cell_type":"markdown","id":"57a550dd-cadd-4895-9967-9e42c3a849c3","metadata":{"id":"57a550dd-cadd-4895-9967-9e42c3a849c3"},"source":["# LlamaIndex\n","\n","LlamaIndex is a framework designed to help you build applications powered by Large Language Models such as chatbots, AI assistants, and translation tools. One of its most valuable capabilities is enriching the knowledge of your LLM with **your own data**, enabling the model to answer questions about **personal, organizational, or domain-specific information** that it wasn’t originally trained on."]},{"cell_type":"markdown","id":"733ee605-2d9c-4de0-990a-f039e812513c","metadata":{"id":"733ee605-2d9c-4de0-990a-f039e812513c"},"source":["# 1. Data Connectors\n","\n","LlamaIndex uses data connectors to **ingest information** from a wide range of **structured and unstructured sources**.\n","\n","The simplest way to load the data is using `SimpleDirectoryReader` which supports various file types such as:\n","\n","- csv - comma-separated values\n","- docx - Microsoft Word\n","- ipynb - Jupyter Notebook\n","- pdf - Portable Document Format\n","- ppt, .pptm, .pptx - Microsoft PowerPoint\n","- ...and many more.\n","\n","Data connector takes your data from these different formats and put them together in a uniform, organized way so they can be used within your LLM application.\n","\n","You can find all supported file types in [the documentation](https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/#simpledirectoryreader).\n","\n","Let's import `SimpleDirectoryReader`:"]},{"cell_type":"code","execution_count":null,"id":"3cf0f9d3-0997-485f-8423-d15a81803388","metadata":{"id":"3cf0f9d3-0997-485f-8423-d15a81803388"},"outputs":[],"source":["from llama_index.core import SimpleDirectoryReader"]},{"cell_type":"markdown","id":"17628016-069e-4ba8-b631-c02b0cebcf58","metadata":{"id":"17628016-069e-4ba8-b631-c02b0cebcf58"},"source":["We will load the PDF file called \"charter.pdf\" (stored in \"data\" folder in notebook's directory) containing the Charter of Fundamental Rights of the European Union.  \n","\n","> NOTE: In this notebook we will use the asynchronous (async) versions of data connectors using `await` and `.aload_data()`. It helps everything run more smoothly and prevents technical errors with the notebook’s event loop. You don’t need to understand all the internals, just know that `await` is the keyword that tells Python \"this step might take a while, pause here until it’s done\".\n"]},{"cell_type":"code","execution_count":null,"id":"e099daaa-3f6a-4ec7-bf14-07b98c924fa9","metadata":{"id":"e099daaa-3f6a-4ec7-bf14-07b98c924fa9"},"outputs":[],"source":["# Generating documents\n","documents = await SimpleDirectoryReader(input_files = [\"data/charter.pdf\"]).aload_data()"]},{"cell_type":"markdown","id":"2af3a19a-770a-4d0a-8ff7-9ea41b9773a8","metadata":{"id":"2af3a19a-770a-4d0a-8ff7-9ea41b9773a8"},"source":["When this data connector processes a PDF, it doesn’t treat the whole file as a single block of text. Instead, it splits the PDF into pages and each page is returned as **document object**."]},{"cell_type":"code","execution_count":null,"id":"7b81ecc4-0800-4708-acb9-d226c51c644e","metadata":{"id":"7b81ecc4-0800-4708-acb9-d226c51c644e","outputId":"4c428aa3-29b6-4c5f-b8d4-d8e5db41ac86"},"outputs":[{"data":{"text/plain":["17"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# The number of pages in the original PDF file == The number of document objects\n","len(documents)"]},{"cell_type":"markdown","id":"5b4ca01e-80fc-4b27-b0fb-62df1231dbd6","metadata":{"id":"5b4ca01e-80fc-4b27-b0fb-62df1231dbd6"},"source":["Let's display the text of the second document where we can see the Table of Contents:"]},{"cell_type":"code","execution_count":null,"id":"3bfe1297-608b-48b5-87bd-82b75fe4b90a","metadata":{"id":"3bfe1297-608b-48b5-87bd-82b75fe4b90a","outputId":"83ff777c-9aa5-4713-d2c8-4f3bf5f5311f"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \n","Table of Contents  \n","Page \n","PREAMBLE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393  \n","TITLE I DIGNITY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394  \n","TITLE II FREEDOMS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395  \n","TITLE III EQUALITY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397  \n","TITLE IV SOLIDARITY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399  \n","TITLE V CITIZENS' RIGHTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401  \n","TITLE VI JUSTICE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 403  \n","TITLE VII GENERAL PROVISIONS GOVERNING THE INTERPRETATION AND \n","APPLICATION OF THE CHARTER . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404\n","EN C 202/390 Official Journal of the European Union 7.6.2016\n"]}],"source":["print(documents[1].text)"]},{"cell_type":"markdown","id":"281e13be-433d-4da1-b332-d7bf5c252024","metadata":{"id":"281e13be-433d-4da1-b332-d7bf5c252024"},"source":["Each document include metadata such as `file_name`, `file_type`, `creation_date`, etc.:"]},{"cell_type":"code","execution_count":null,"id":"27457d8d-7ca6-4ebf-bff2-fb0f7c985caf","metadata":{"id":"27457d8d-7ca6-4ebf-bff2-fb0f7c985caf","outputId":"85df09f5-b2e6-45de-eafb-bb4a21b4a01a"},"outputs":[{"data":{"text/plain":["{'page_label': '390',\n"," 'file_name': 'charter.pdf',\n"," 'file_path': 'data/charter.pdf',\n"," 'file_type': 'application/pdf',\n"," 'file_size': 1049657,\n"," 'creation_date': '2025-08-19',\n"," 'last_modified_date': '2025-08-19'}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["documents[1].metadata"]},{"cell_type":"markdown","id":"64e04732-f224-4008-9835-d89e61c6396f","metadata":{"id":"64e04732-f224-4008-9835-d89e61c6396f"},"source":["# 2. Creating the Index and Querying\n","Next, we’ll build a vector database to store our embeddings. We'll use `VectorStoreIndex.from_documents()` which automatically **breaks each document into smaller pieces called nodes** based on length. Each node keeps the metadata of its parent document, so we don’t lose context. Once the nodes are created, they are passed to an embedding model - `text-embedding-ada-002` from OpenAI by default."]},{"cell_type":"code","execution_count":null,"id":"88396a76-7874-431e-86aa-ddc4b51ca3f4","metadata":{"id":"88396a76-7874-431e-86aa-ddc4b51ca3f4","outputId":"6484d7c3-1953-442c-9959-6aebfbd38e90"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 17:59:45,969 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]}],"source":["# Creating the index\n","from llama_index.core import VectorStoreIndex\n","index = VectorStoreIndex.from_documents(documents)"]},{"cell_type":"markdown","id":"b7744064-5b4e-4637-8afb-1868db1b3deb","metadata":{"id":"b7744064-5b4e-4637-8afb-1868db1b3deb"},"source":["Next, we’ll turn the index into a query engine so that we can ask questions.\n","\n","Behind the scenes, the workflow looks like this:\n","1. **Query Embedding**: Our text query is embedded into a vector\n","2. **Retriever**: Query vector is compared against the embeddings stored in the index and retriever returns the most relevant nodes - LlamaIndex uses **cosine** similarity by default\n","3. **Response Syntethizer**: Combines the retrieved nodes with our query to generate a prompt, which is then passed to an LLM to produce an answer - LlamaIndex uses `gpt-3.5-turbo` from OpenAI by default."]},{"cell_type":"code","execution_count":null,"id":"44e4cafa-0e35-43be-b796-c45bdfafa681","metadata":{"id":"44e4cafa-0e35-43be-b796-c45bdfafa681","outputId":"b9800c4c-21fd-414b-b269-a0db06e276c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 18:01:07,684 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","2025-09-18 18:01:09,009 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Title I is about fundamental human rights and dignity, emphasizing the protection and respect for human life, integrity, and prohibiting practices such as the death penalty, torture, slavery, and discrimination.\n"]}],"source":["# Setting the index as query engine\n","query_engine = index.as_query_engine()\n","\n","# Querying\n","print(query_engine.query(\"What is Title 1 about?\"))"]},{"cell_type":"markdown","id":"238e0789-edaf-407b-a511-83865378d43a","metadata":{"id":"238e0789-edaf-407b-a511-83865378d43a"},"source":["# 3. Making Data Persistent\n","\n","By default, `VectorStoreIndex` keeps all data in memory. However, LlamaIndex has its own built-in persistence mechanism.\n","\n","We will use `persist()` method that handle saving the index into \"my_storage\". In the code cell below, if folder \"my_storage\" does not exist yet the code will:\n","- load PDF file from \"data\" folder\n","- build a new index\n","- persist that index to disk inside \"my storage\"\n","\n","If folder \"my_storage\" already exists, the code instead:\n","- creates `StorageContext` object pointing to this folder\n","- reload the previously saved index directly"]},{"cell_type":"code","execution_count":null,"id":"db1e515c-786f-4720-9e5b-828bcbc05a80","metadata":{"id":"db1e515c-786f-4720-9e5b-828bcbc05a80","outputId":"73a0d749-f04f-4042-e144-a70c5b77c0a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 18:06:01,779 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"]}],"source":["import os\n","import os.path\n","from llama_index.core import StorageContext, load_index_from_storage\n","\n","# A directory\n","PERSIST_DIR = \"./my_storage\"\n","\n","if not os.path.exists(PERSIST_DIR):\n","    # Loading the documents and creating the index\n","    documents = await SimpleDirectoryReader(input_files = [\"data/charter.pdf\"]).aload_data()\n","    index = VectorStoreIndex.from_documents(documents)\n","    # Storing\n","    index.storage_context.persist(persist_dir = PERSIST_DIR)\n","else:\n","    # Reloading the existing index\n","    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n","    index = load_index_from_storage(storage_context)"]},{"cell_type":"markdown","id":"8317c4d8-8841-45e2-b182-0f0234fd7d37","metadata":{"id":"8317c4d8-8841-45e2-b182-0f0234fd7d37"},"source":["Now we can start running queries against it:"]},{"cell_type":"code","execution_count":null,"id":"28cb3f47-6391-447c-92b2-6a9cefbd6a24","metadata":{"id":"28cb3f47-6391-447c-92b2-6a9cefbd6a24","outputId":"1bd26224-7b92-49d1-da13-35c560554e76"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 18:07:16,020 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","2025-09-18 18:07:16,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Title II of the document focuses on various freedoms. It covers the right to liberty and security, respect for private and family life, protection of personal data, the right to marry and found a family, freedom of thought, conscience, and religion.\n"]}],"source":["query_engine = index.as_query_engine()\n","response = query_engine.query(\"Can you summarize Title 2?\")\n","print(response)"]},{"cell_type":"markdown","id":"eef28516-0636-47b7-93b1-b6858d50d9e2","metadata":{"id":"eef28516-0636-47b7-93b1-b6858d50d9e2"},"source":["# 4. LlamaParse\n","\n","If your dataset includes different file types or documents with complex layouts (such as tables, multi-column text or embedded images), you can use `LlamaParse`. This parser is part of LlamaCloud and is designed to convert documents into structured outputs while preserving layout features far more accurately than generic readers.\n","\n","To use this parser, you’ll first need **LlamaCloud account**. Go to www.llamaindex.ai and sign-up. Then navigate to **API keys** section and click **Generate New Key**. Be sure to copy and store this secret key in a safe place. For security reasons, it will not be shown again in your account.\n","\n","> NOTE: You can also make your LlamaParse API key and base URL load automatically every time your terminal starts. This way, you don’t have to set them manually in every session. Open your terminal and edit your shell file - type `nano ~/.zshrc`. At the end of the file, add the following lines. Then run `source ~/.zshrc`.\n",">\n","> `export LLAMA_CLOUD_API_KEY=\"YOUR_EU_KEY\"`\n",">\n","> `export LLAMA_CLOUD_API_BASE=\"api.cloud.eu.llamaindex.ai\"`\n"]},{"cell_type":"code","execution_count":null,"id":"1308eb87-edd2-408b-a553-4ab9fb3eb155","metadata":{"id":"1308eb87-edd2-408b-a553-4ab9fb3eb155"},"outputs":[],"source":["from llama_parse import LlamaParse\n","\n","parser = LlamaParse(\n","    result_type = \"text\",\n","    base_url = \"https://api.cloud.eu.llamaindex.ai\",  # Calling the EU LlamaCloud endpoint\n","    verbose = True\n",")"]},{"cell_type":"code","execution_count":null,"id":"82c5e62b-b049-48bc-8838-f55d3f537af8","metadata":{"id":"82c5e62b-b049-48bc-8838-f55d3f537af8","outputId":"51fb71fa-2dab-493f-b8ec-a3d8aef820d5"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 18:14:35,826 - INFO - HTTP Request: POST https://api.cloud.eu.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Started parsing the file under job_id d641e88d-b25c-4e08-b607-bae12af278df\n"]},{"name":"stderr","output_type":"stream","text":["2025-09-18 18:14:37,193 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/d641e88d-b25c-4e08-b607-bae12af278df \"HTTP/1.1 200 OK\"\n","2025-09-18 18:14:39,717 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/d641e88d-b25c-4e08-b607-bae12af278df \"HTTP/1.1 200 OK\"\n","2025-09-18 18:14:43,608 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/d641e88d-b25c-4e08-b607-bae12af278df \"HTTP/1.1 200 OK\"\n","2025-09-18 18:14:48,114 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/d641e88d-b25c-4e08-b607-bae12af278df \"HTTP/1.1 200 OK\"\n","2025-09-18 18:14:51,882 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/d641e88d-b25c-4e08-b607-bae12af278df/result/text \"HTTP/1.1 200 OK\"\n"]}],"source":["documents = await parser.aload_data(\"./data/charter.pdf\")"]},{"cell_type":"markdown","id":"48985328-aa5c-4b53-8ea8-654aba43978c","metadata":{"id":"48985328-aa5c-4b53-8ea8-654aba43978c"},"source":["Let's again display the text of the second document - the parser preserves layout features like headings better than a simple text extractor like `SimpleDirectoryReader`:"]},{"cell_type":"code","execution_count":null,"id":"35139e0d-ef03-4847-a604-033d633b723a","metadata":{"id":"35139e0d-ef03-4847-a604-033d633b723a","outputId":"532b9e84-6899-431d-d8d0-940d21e3aef9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","C 202/390  EN                     Official Journal of the European Union                                                                      7.6.2016\n","\n","                                          Table of Contents\n","\n","                                                                                                                                              Page\n","\n","           PREAMBLE      . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .        393\n","\n","           TITLE I       DIGNITY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .              394\n","\n","           TITLE II      FREEDOMS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                 395\n","\n","           TITLE III     EQUALITY              . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    397\n","\n","           TITLE IV      SOLIDARITY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                 399\n","\n","           TITLE V       CITIZENS' RIGHTS                  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    401\n","\n","           TITLE VI      JUSTICE           . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .    403\n","\n","           TITLE VII     GENERAL  PROVISIONS GOVERNING THE INTERPRETATION   AND\n","                         APPLICATION OF THE CHARTER . . . . . . . . . . . . . . . . . . . . . . . . . . . . .                                 404\n","\n"]}],"source":["print(documents[1].text)"]},{"cell_type":"markdown","id":"2f3c2a32-6f7d-4ad4-aa51-774c83e06a3d","metadata":{"id":"2f3c2a32-6f7d-4ad4-aa51-774c83e06a3d"},"source":["## 4.1 Using LlamaParse - PDF with tables into Markdown"]},{"cell_type":"markdown","id":"321c3210-e505-442b-923f-932461353ff7","metadata":{"id":"321c3210-e505-442b-923f-932461353ff7"},"source":["Now let’s try `LlamaParse` on PDF called \"livestock_poultry.pdf\" that contains not only the text but also **several tables**. `LlamaParse` will return the content in **Markdown format** which makes the document far easier for an LLM to interpret.\n","\n","In the code cell below, we initialize the parser that connects to the LlamaCloud API - we need to set `base_url` that specifies which regional LlamaCloud endpoint to use. In this case, we’re pointing to the EU server."]},{"cell_type":"code","execution_count":null,"id":"59530382-d441-4f6f-929d-d278f352b748","metadata":{"id":"59530382-d441-4f6f-929d-d278f352b748"},"outputs":[],"source":["# Parsing PDF\n","parser = LlamaParse(\n","    result_type = \"markdown\",\n","    base_url = \"https://api.cloud.eu.llamaindex.ai\",\n","    verbose = True\n",")"]},{"cell_type":"markdown","id":"3191c952-183d-406e-b6dc-8db637bcc6d3","metadata":{"id":"3191c952-183d-406e-b6dc-8db637bcc6d3"},"source":["Now we can send a PDF file to the parser:"]},{"cell_type":"code","execution_count":null,"id":"a2dfbe2a-102b-47d2-b687-d36cc26519a1","metadata":{"id":"a2dfbe2a-102b-47d2-b687-d36cc26519a1","outputId":"c7c4895c-803d-432a-bf77-f340f3194d56"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 18:38:46,624 - INFO - HTTP Request: POST https://api.cloud.eu.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Started parsing the file under job_id 75c128e5-afaf-49e4-95b6-329aeea0f8d6\n"]},{"name":"stderr","output_type":"stream","text":["2025-09-18 18:38:48,377 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:38:50,851 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:38:54,262 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:38:58,606 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:39:04,647 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:39:10,175 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:39:15,605 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:39:21,171 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:39:27,891 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:39:28,436 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/75c128e5-afaf-49e4-95b6-329aeea0f8d6/result/markdown \"HTTP/1.1 200 OK\"\n"]}],"source":["pdf_doc = await parser.aload_data(\"./data/livestock_poultry.pdf\")"]},{"cell_type":"markdown","id":"069e7d49-c696-40ff-9cc0-7d005f6ae210","metadata":{"id":"069e7d49-c696-40ff-9cc0-7d005f6ae210"},"source":["Let's print the document with index 8. Compare this Markdown output with the original PDF (page 9). Notice how the layout is preserved. This is what makes `LlamaParse` valuable: instead of flattening tables into plain text, it captures structure in a way that downstream models can use effectively."]},{"cell_type":"code","execution_count":null,"id":"770e1f2d-25d6-49c6-ae7a-49c425514027","metadata":{"id":"770e1f2d-25d6-49c6-ae7a-49c425514027","outputId":"d9d9f48d-9705-4610-ea6c-61550fc75b4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","# Cattle Stocks - Top Countries Summary\n","\n","# (in 1,000 head)\n","\n","|                        | 2021    | 2022    | 2023    | 2024    | 2025    | 2025    |\n","| ---------------------- | ------- | ------- | ------- | ------- | ------- | ------- |\n","| Total Cattle Beg. Stks |         |         |         |         | Oct     | Apr     |\n","| India                  | 305,500 | 306,700 | 307,400 | 307,420 | 307,490 | 307,490 |\n","| Brazil                 | 193,195 | 193,780 | 194,365 | 192,572 | 186,875 | 186,875 |\n","| China                  | 95,621  | 98,172  | 102,160 | 105,090 | 104,000 | 104,900 |\n","| European Union         | 76,551  | 75,705  | 74,808  | 73,745  | 72,300  | 71,822  |\n","| Argentina              | 53,540  | 53,400  | 54,100  | 52,800  | 53,200  | 52,370  |\n","| Australia              | 23,021  | 23,944  | 25,800  | 27,080  | 27,020  | 27,260  |\n","| Mexico                 | 17,000  | 17,314  | 17,763  | 17,840  | 17,735  | 17,965  |\n","| Russia                 | 17,953  | 17,798  | 17,435  | 17,285  | 16,650  | 17,050  |\n","| Uruguay                | 11,966  | 11,646  | 11,795  | 11,366  | 11,805  | 11,805  |\n","| Canada                 | 11,515  | 11,515  | 11,245  | 11,015  | 10,935  | 10,940  |\n","| Others                 | 38,040  | 38,309  | 38,055  | 29,097  | 28,681  | 28,639  |\n","| Total Foreign          | 843,902 | 848,283 | 854,926 | 845,310 | 836,691 | 837,116 |\n","| United States          | 93,587  | 91,789  | 88,841  | 87,157  | 86,000  | 86,662  |\n","| Total                  | 937,489 | 940,072 | 943,767 | 932,467 | 922,691 | 923,778 |\n","\n","# Production (Calf Crop)\n","\n","|                | 2021    | 2022    | 2023    | 2024    | 2025    | 2025    |\n","| -------------- | ------- | ------- | ------- | ------- | ------- | ------- |\n","| India          | 69,800  | 70,000  | 70,200  | 70,580  | 71,030  | 71,030  |\n","| China          | 50,525  | 53,240  | 54,138  | 52,000  | 52,000  | 50,000  |\n","| Brazil         | 46,550  | 47,836  | 48,000  | 47,500  | 47,800  | 47,250  |\n","| European Union | 25,050  | 24,650  | 23,720  | 23,350  | 23,300  | 23,200  |\n","| Argentina      | 14,460  | 15,100  | 14,700  | 14,500  | 14,800  | 14,700  |\n","| Australia      | 8,200   | 8,760   | 9,500   | 9,800   | 10,000  | 10,300  |\n","| Mexico         | 8,150   | 8,350   | 8,475   | 8,600   | 8,700   | 8,700   |\n","| Russia         | 6,600   | 6,525   | 6,600   | 6,650   | 6,300   | 6,600   |\n","| New Zealand    | 5,460   | 5,159   | 5,120   | 5,000   | 5,000   | 5,000   |\n","| Canada         | 4,482   | 4,427   | 4,316   | 4,296   | 4,280   | 4,270   |\n","| Others         | 11,974  | 11,871  | 11,099  | 9,693   | 9,305   | 9,440   |\n","| Total Foreign  | 251,251 | 255,918 | 255,868 | 251,969 | 252,515 | 250,490 |\n","| United States  | 35,131  | 34,440  | 33,563  | 33,530  | 32,700  | 33,300  |\n","| Total          | 286,382 | 290,358 | 289,431 | 285,499 | 285,215 | 283,790 |\n","\n","Notes: May contain other bovines. The notation of a month beneath a year conveys the month in which the forecast for that year was released.\n","\n","Foreign Agricultural Service/USDA     9     April 2025\n","# Global Market Analysis\n","\n"]}],"source":["print(pdf_doc[8].text[:10000])"]},{"cell_type":"markdown","id":"82296aeb-b730-44b1-8b92-d0a3c3f4ebf7","metadata":{"id":"82296aeb-b730-44b1-8b92-d0a3c3f4ebf7"},"source":["## 4.2 Parsing different file types\n","\n","In this section, we’ll see how to use LlamaParse to handle documents of different types, such as PDFs and Word files, and bring them into a single search workflow.\n","\n","Instead of writing separate code for each format, we can map file extensions to the same parser and let `SimpleDirectoryReader` automatically process everything in a folder.\n","\n","First, we'll initialize a parser:"]},{"cell_type":"code","execution_count":null,"id":"2872fa69-834c-47b6-863a-1305840b275e","metadata":{"id":"2872fa69-834c-47b6-863a-1305840b275e"},"outputs":[],"source":["parser = LlamaParse(result_type = \"markdown\",\n","                    base_url = \"https://api.cloud.eu.llamaindex.ai\",\n","                    verbose = True)"]},{"cell_type":"markdown","id":"d60acec6-275e-4ff5-948c-6329180398ae","metadata":{"id":"d60acec6-275e-4ff5-948c-6329180398ae"},"source":["Next, we'll map file extensions to the parser:"]},{"cell_type":"code","execution_count":null,"id":"909ca439-32d8-4f6f-ab65-1b1b0d261022","metadata":{"id":"909ca439-32d8-4f6f-ab65-1b1b0d261022"},"outputs":[],"source":["file_extractor = {\n","    \".pdf\": parser,\n","    \".docx\": parser\n","}"]},{"cell_type":"markdown","id":"4c18225d-f46b-4b7d-8f19-3eec78bc09b7","metadata":{"id":"4c18225d-f46b-4b7d-8f19-3eec78bc09b7"},"source":["Now we can tell `SimpleDirectoryReader` to scan a folder with files \"charter.pdf\", \"livestock_poultry.pdf\" and \"vacation_policy.docx\". If it finds a `.pdf` or `.docx`, it will use our parser to process it. The result is a list of document objects where each page or section is stored as Markdown text."]},{"cell_type":"code","execution_count":null,"id":"09339a6a-c221-485b-bf3b-9ec7453f501d","metadata":{"id":"09339a6a-c221-485b-bf3b-9ec7453f501d","outputId":"c54c235f-030b-4d0f-88a8-cc69b398be76"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 18:58:30,085 - INFO - HTTP Request: POST https://api.cloud.eu.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:30,141 - INFO - HTTP Request: POST https://api.cloud.eu.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Started parsing the file under job_id 444ca46f-544e-49b4-8b01-7f23e85f6e7b\n","Started parsing the file under job_id 91f803e4-c119-4fa2-9769-6accecbb9a03\n"]},{"name":"stderr","output_type":"stream","text":["2025-09-18 18:58:30,986 - INFO - HTTP Request: POST https://api.cloud.eu.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Started parsing the file under job_id 2c3820d1-0af8-4c57-ad95-566d77e20498\n"]},{"name":"stderr","output_type":"stream","text":["2025-09-18 18:58:31,638 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/444ca46f-544e-49b4-8b01-7f23e85f6e7b \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:31,642 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/91f803e4-c119-4fa2-9769-6accecbb9a03 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:32,574 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/2c3820d1-0af8-4c57-ad95-566d77e20498 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:33,879 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/91f803e4-c119-4fa2-9769-6accecbb9a03 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:34,506 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/444ca46f-544e-49b4-8b01-7f23e85f6e7b \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:34,764 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/2c3820d1-0af8-4c57-ad95-566d77e20498 \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:35,036 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/91f803e4-c119-4fa2-9769-6accecbb9a03/result/markdown \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:35,204 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/2c3820d1-0af8-4c57-ad95-566d77e20498/result/markdown \"HTTP/1.1 200 OK\"\n","2025-09-18 18:58:38,177 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/444ca46f-544e-49b4-8b01-7f23e85f6e7b \"HTTP/1.1 200 OK\"\n","2025-09-18 18:59:05,841 - INFO - HTTP Request: GET https://api.cloud.eu.llamaindex.ai/api/parsing/job/444ca46f-544e-49b4-8b01-7f23e85f6e7b/result/markdown \"HTTP/1.1 200 OK\"\n"]}],"source":["documents = await SimpleDirectoryReader(\n","    input_dir = \"./data/\",\n","    file_extractor = file_extractor\n",").aload_data()"]},{"cell_type":"markdown","id":"abf3d766-db07-496a-970c-81862c3c8ace","metadata":{"id":"abf3d766-db07-496a-970c-81862c3c8ace"},"source":["Now we are going to create embeddings for our documents. As we already know, when we build `VectorStoreIndex`, it automatically splits text into chunks before embedding, but this uses default settings.\n","\n","However, we can use `SentenceSplitter` to gain explicit control over how that chunking happens:\n","- `chunk_size`: sets the maximum length of each chunk (keeps chunks small enough to fit into the embedding model and LLM context window)\n","- `chunk_overlap`: defines how much content is repeated between consecutive chunks\n"]},{"cell_type":"code","execution_count":null,"id":"2c55b6fe-1b88-46f3-bfd1-c73d5575cbab","metadata":{"id":"2c55b6fe-1b88-46f3-bfd1-c73d5575cbab"},"outputs":[],"source":["from llama_index.core.node_parser import SentenceSplitter\n","\n","# Split into nodes (chunks)\n","splitter = SentenceSplitter(\n","    chunk_size = 512,        # each chunk will be about 512 characters/tokens long\n","    chunk_overlap = 50)      # the last 50 characters/tokens of one chunk will also appear at the start of the next\n","\n","nodes = splitter.get_nodes_from_documents(documents)"]},{"cell_type":"markdown","id":"5a935fea-6afc-4166-a2cd-b21c7558fff4","metadata":{"id":"5a935fea-6afc-4166-a2cd-b21c7558fff4"},"source":["The next step is to build a vector index:"]},{"cell_type":"code","execution_count":null,"id":"d25eafd0-9a8f-458e-8aaa-612e8032aee5","metadata":{"id":"d25eafd0-9a8f-458e-8aaa-612e8032aee5"},"outputs":[],"source":["# Creating embeddings from \"nodes\"\n","index = VectorStoreIndex.from_documents(nodes)\n","\n","# Wrapping the index in a query engine\n","query_engine = index.as_query_engine()"]},{"cell_type":"markdown","id":"50fa25c2-0fe6-4333-959d-7bc2cf91d615","metadata":{"id":"50fa25c2-0fe6-4333-959d-7bc2cf91d615"},"source":["In the code cell below, the question is converted into a vector embedding which is compared against all stored embeddings (nodes) in the vector index. The nodes whose embeddings are most similar (highest cosine score) are selected as \"relevant\" and combined with the query and passed to an LLM to generate the answer:"]},{"cell_type":"code","execution_count":null,"id":"1dfaa2a2-85e4-4683-b860-7116d3563250","metadata":{"id":"1dfaa2a2-85e4-4683-b860-7116d3563250","outputId":"8616b2d0-770b-48e1-91ed-6d2d89989f79"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 19:22:46,634 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","2025-09-18 19:22:47,888 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","2025-09-18 19:22:49,890 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["Up to 10 unused vacation days may be carried over into the next calendar year.\n"]}],"source":["# Running the query\n","print(query_engine.query(\"How many days can be carried over into the next calendar year?\"))"]},{"cell_type":"code","execution_count":null,"id":"60ddadc8-0e90-4ebf-a006-782c8fdb0549","metadata":{"id":"60ddadc8-0e90-4ebf-a006-782c8fdb0549","outputId":"30200111-1bb0-496a-a80b-2fd93fd885b1"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 19:23:10,315 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","2025-09-18 19:23:11,031 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["China, Philippines, Chile, Japan, Hong Kong\n"]}],"source":["# Running the query\n","print(query_engine.query(\"What are brazil top five pork export markets?\"))"]},{"cell_type":"code","execution_count":null,"id":"da364cab-afa1-4f43-bb5c-a8bca167523d","metadata":{"id":"da364cab-afa1-4f43-bb5c-a8bca167523d","outputId":"8d99b7d0-49f2-4965-8e55-5ad6aa5392c8"},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-09-18 19:32:37,467 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n","2025-09-18 19:32:42,601 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"]},{"name":"stdout","output_type":"stream","text":["The citizens' rights include the right to vote and stand as a candidate at elections to the European Parliament and municipal elections, the right to good administration, the right of access to documents, the right to refer cases of maladministration to the European Ombudsman, the right to petition the European Parliament, and the freedom of movement and residence within the territory of the Member States.\n"]}],"source":["# Running the query\n","print(query_engine.query(\"What are the citizens' rights?\"))"]},{"cell_type":"markdown","id":"5335c92d-a988-41af-afd7-aea53b68fae1","metadata":{"id":"5335c92d-a988-41af-afd7-aea53b68fae1"},"source":["## 4.5 Using different LLM\n","\n","Up to now, we’ve built a vector index using the default embedding model and the default LLM. But both of these can be customized. By default, LlamaIndex uses OpenAI’s `text-embedding-ada-002` for embeddings and `gpt-3.5-turbo` for the LLM.\n","\n","In the example below, we’ll rebuild our index with a different embedding model - `text-embedding-3-small`, and then use a different LLM - `gpt-4o-mini` to generate answers:"]},{"cell_type":"code","execution_count":null,"id":"fa706ddf-d0f2-4a8e-a9f1-4f1d03d527b1","metadata":{"id":"fa706ddf-d0f2-4a8e-a9f1-4f1d03d527b1"},"outputs":[],"source":["from llama_index.embeddings.openai import OpenAIEmbedding\n","\n","# Building a new index + new embedding model\n","pdf_index = VectorStoreIndex.from_documents(\n","    pdf_doc,\n","    embedding = OpenAIEmbedding(model = \"text-embedding-3-small\")\n",")"]},{"cell_type":"code","execution_count":null,"id":"324b30fc-6068-45eb-ae39-b90dd3df316c","metadata":{"id":"324b30fc-6068-45eb-ae39-b90dd3df316c"},"outputs":[],"source":["from llama_index.llms.openai import OpenAI\n","\n","# Using new LLM\n","query_engine = index.as_query_engine(llm = OpenAI(model=\"gpt-4o-mini\"))\n","response = query_engine.query(\"What is the forecasted percentage change of global export of pork between 2024 and 2025?\")\n","print(response)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}