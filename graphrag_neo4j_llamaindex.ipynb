{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔗 GraphRAG: Combining Graph Databases with Vector Search\n",
    "\n",
    "## Welcome to GraphRAG!\n",
    "\n",
    "In this notebook, you'll learn how to build **GraphRAG** (Graph Retrieval-Augmented Generation) systems that combine the power of:\n",
    "- **Graph databases** (Neo4j) for understanding relationships\n",
    "- **Vector embeddings** for semantic similarity search\n",
    "- **LLMs** (GPT-5-nano) for intelligent entity extraction and query generation\n",
    "\n",
    "## 🎯 What You'll Learn\n",
    "\n",
    "- How to automatically extract entities and relationships from unstructured text using LLMs\n",
    "- Building knowledge graphs programmatically with LlamaIndex\n",
    "- Creating vector embeddings for semantic search\n",
    "- Combining graph traversal with vector similarity for superior retrieval\n",
    "- When GraphRAG outperforms traditional RAG systems\n",
    "\n",
    "## 💼 Why GraphRAG Matters\n",
    "\n",
    "Traditional RAG (Retrieval-Augmented Generation) retrieves documents based on **semantic similarity alone**. This works well for simple questions, but fails when:\n",
    "\n",
    "- **Multi-hop reasoning** is needed (\"Who worked with people who know experts in NLP?\")\n",
    "- **Relationships matter** (\"Show me all projects connected to the Data Science team\")\n",
    "- **Entity disambiguation** is required (distinguishing between multiple people named \"John\")\n",
    "- **Structured knowledge** improves context (organizational hierarchies, citation networks)\n",
    "\n",
    "**GraphRAG solves these problems** by:\n",
    "1. Extracting entities and relationships using LLMs\n",
    "2. Building a knowledge graph that captures structure\n",
    "3. Using vector search to find relevant entities\n",
    "4. Traversing the graph to gather rich, connected context\n",
    "5. Providing LLMs with both semantically similar AND structurally related information\n",
    "\n",
    "## 🔗 Building on Notebook 1\n",
    "\n",
    "You've already learned:\n",
    "- Graph database concepts (nodes, relationships, properties)\n",
    "- Cypher query language for pattern matching\n",
    "- Manual knowledge graph construction\n",
    "\n",
    "Now you'll automate everything using:\n",
    "- **LLM-powered entity extraction** (GPT-5-nano)\n",
    "- **LlamaIndex** for document processing and retrieval\n",
    "- **Hybrid search** combining vectors and graphs\n",
    "\n",
    "Let's begin! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 📚 Part 1: Theory - Understanding GraphRAG\n",
    "\n",
    "### What is GraphRAG?\n",
    "\n",
    "**GraphRAG** (Graph Retrieval-Augmented Generation) is an advanced RAG technique that enhances traditional vector-based retrieval with graph database capabilities. Instead of only finding semantically similar documents, GraphRAG understands **how entities are connected**.\n",
    "\n",
    "### Traditional RAG vs. GraphRAG\n",
    "\n",
    "**Traditional RAG:**\n",
    "1. Chunk documents into passages\n",
    "2. Create vector embeddings for each chunk\n",
    "3. User asks a question\n",
    "4. Find top-K most similar chunks\n",
    "5. Pass chunks to LLM for answer generation\n",
    "\n",
    "**Limitations:**\n",
    "- No understanding of relationships between entities\n",
    "- Can't answer \"who knows whom\" or \"what's connected to what\"\n",
    "- Misses context from related but not semantically similar documents\n",
    "- Poor performance on multi-hop questions\n",
    "\n",
    "**GraphRAG:**\n",
    "1. Extract entities and relationships from documents using LLMs\n",
    "2. Build a knowledge graph (nodes = entities, edges = relationships)\n",
    "3. Create vector embeddings for both documents AND entities\n",
    "4. User asks a question\n",
    "5. Find relevant entities via vector search\n",
    "6. Traverse the graph to find connected entities and documents\n",
    "7. Combine semantically similar and structurally related context\n",
    "8. Pass enriched context to LLM for answer generation\n",
    "\n",
    "**Advantages:**\n",
    "- ✅ Understands relationships (\"Sarah manages Marcus who works on Project X\")\n",
    "- ✅ Multi-hop reasoning (\"Find experts connected to AI researchers in our network\")\n",
    "- ✅ Entity disambiguation (distinguishing between different \"John Smiths\")\n",
    "- ✅ Richer context from connected entities\n",
    "- ✅ Explainable retrieval paths (\"I found this via Sarah → Project X → Document Y\")\n",
    "\n",
    "### 🔑 Key Components of GraphRAG\n",
    "\n",
    "1. **Entity Extraction**: Use LLMs to identify entities (people, organizations, concepts) in text\n",
    "2. **Relationship Extraction**: Identify how entities are connected\n",
    "3. **Knowledge Graph Construction**: Store entities and relationships in a graph database\n",
    "4. **Vector Embeddings**: Create semantic representations of entities and documents\n",
    "5. **Hybrid Retrieval**: Combine vector similarity with graph traversal\n",
    "6. **Context Assembly**: Gather relevant information from multiple sources\n",
    "7. **LLM Generation**: Generate answers using enriched context\n",
    "\n",
    "### 🌟 Real-World Use Cases\n",
    "\n",
    "1. **Enterprise Knowledge Management**: \"Find all documents related to projects that Sarah's team collaborated on with Engineering\"\n",
    "2. **Research Paper Discovery**: \"Show me papers cited by NLP experts who also published on transformers\"\n",
    "3. **Customer Support**: \"Find solutions used by customers in similar industries with related issues\"\n",
    "4. **Legal Document Analysis**: \"Identify all cases related to this statute through precedent citations\"\n",
    "5. **Medical Knowledge Graphs**: \"Find treatment protocols for conditions related to this patient's diagnosis\"\n",
    "\n",
    "### 💡 Key Point: When to Use GraphRAG\n",
    "\n",
    "Use **GraphRAG** when:\n",
    "- Your domain has rich entity relationships (organizational, citation, social networks)\n",
    "- Questions require multi-hop reasoning\n",
    "- Entity disambiguation is important\n",
    "- Relationships are as important as content similarity\n",
    "\n",
    "Use **Traditional RAG** when:\n",
    "- Documents are mostly independent\n",
    "- Simple semantic similarity is sufficient\n",
    "- Lower complexity and faster implementation are priorities\n",
    "\n",
    "### 🎯 Key Takeaways\n",
    "\n",
    "- GraphRAG combines vector search with graph traversal for superior retrieval\n",
    "- LLMs extract entities and relationships automatically from text\n",
    "- Knowledge graphs capture structure that vectors alone cannot\n",
    "- Hybrid search provides both semantic and structural relevance\n",
    "- GraphRAG excels at multi-hop reasoning and entity-centric questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k78v1w9suka",
   "source": "---\n## ⚙️ Part 2: Setup - Installing Dependencies\n\nWe'll install everything needed for GraphRAG:\n\n- **Neo4j Community Edition**: Graph database (same as Notebook 1)\n- **LlamaIndex**: Document processing and RAG orchestration framework\n- **OpenAI Python SDK**: For GPT-5-nano API access\n- **ChromaDB**: Vector database for embeddings\n- **Additional libraries**: pandas, networkx, matplotlib for analysis\n\nThis setup takes about 60-90 seconds. Let's begin! ⚡",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7h8tvuc0dp",
   "source": "# 📦 Install Neo4j Community Edition in Colab\n# (Same process as Notebook 1)\n\nimport time\nimport os\n\nprint(\"🔄 Step 1: Installing Java (required for Neo4j)...\")\n!apt-get update -qq > /dev/null 2>&1\n!apt-get install -y default-jre wget > /dev/null 2>&1\nprint(\"✅ Java installed!\\n\")\n\nprint(\"📥 Step 2: Downloading Neo4j Community Edition 4.4.36...\")\n!wget -q https://dist.neo4j.org/neo4j-community-4.4.36-unix.tar.gz\nprint(\"✅ Downloaded!\\n\")\n\nprint(\"📦 Step 3: Extracting Neo4j...\")\n!tar -xf neo4j-community-4.4.36-unix.tar.gz\n!mv neo4j-community-4.4.36 neo4j\nprint(\"✅ Extracted to 'neo4j' folder!\\n\")\n\nprint(\"🔐 Step 4: Setting initial password...\")\n!neo4j/bin/neo4j-admin set-initial-password password123\nprint(\"✅ Password set to: password123\\n\")\n\nprint(\"🚀 Step 5: Starting Neo4j server...\")\n!neo4j/bin/neo4j start\nprint(\"✅ Neo4j starting...\\n\")\n\nprint(\"⏳ Step 6: Waiting for Neo4j to be fully ready...\")\nimport socket\nmax_attempts = 30\nfor attempt in range(max_attempts):\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex(('127.0.0.1', 7687))\n        sock.close()\n        if result == 0:\n            print(f\"✅ Neo4j is ready! (took {attempt * 2} seconds)\\n\")\n            break\n    except:\n        pass\n    if attempt % 5 == 0 and attempt > 0:\n        print(f\"   Still waiting... ({attempt}/{max_attempts})\")\n    time.sleep(2)\n\nprint(\"=\" * 60)\nprint(\"📊 NEO4J CONNECTION DETAILS\")\nprint(\"=\" * 60)\nprint(\"URI:      bolt://localhost:7687\")\nprint(\"Username: neo4j\")\nprint(\"Password: password123\")\nprint(\"=\" * 60)\nprint(\"\\n🎉 Neo4j setup complete!\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "kh37n4vm0m",
   "source": "# 📦 Install Python dependencies for GraphRAG\n\nprint(\"📥 Installing GraphRAG dependencies...\")\nprint(\"This may take 30-60 seconds...\\n\")\n\n# Fix dependency issue first\n!pip install -q jedi\n\n# Core dependencies\n!pip install -q neo4j py2neo\n!pip install -q openai\n!pip install -q llama-index\n!pip install -q llama-index-graph-stores-neo4j\n!pip install -q llama-index-vector-stores-chroma\n!pip install -q llama-index-embeddings-openai\n!pip install -q chromadb\n!pip install -q pandas networkx matplotlib\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"✅ All dependencies installed!\")\nprint(\"\\n📦 Installed packages:\")\nprint(\"  ✓ neo4j, py2neo - Graph database drivers\")\nprint(\"  ✓ openai - GPT-5-nano API access\")\nprint(\"  ✓ llama-index - RAG orchestration framework\")\nprint(\"  ✓ chromadb - Vector database\")\nprint(\"  ✓ pandas, networkx, matplotlib - Data analysis and visualization\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gmhq4j3c57h",
   "source": "# 📚 Import all necessary libraries\n\n# Neo4j for graph database\nfrom neo4j import GraphDatabase\nfrom llama_index.graph_stores.neo4j import Neo4jGraphStore\n\n# LlamaIndex core\nfrom llama_index.core import (\n    Document,\n    VectorStoreIndex,\n    ServiceContext,\n    StorageContext,\n    Settings\n)\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.core.extractors import (\n    TitleExtractor,\n    QuestionsAnsweredExtractor,\n)\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\n\n# ChromaDB for vector storage\nimport chromadb\n\n# Data manipulation and visualization\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom typing import List, Dict, Any, Optional\nimport json\nfrom pprint import pprint\n\nprint(\"✅ All libraries imported successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bxqpa1m2fbm",
   "source": "# Configure OpenAI API key\n# Method 1: Try to get API key from Colab secrets (recommended)\ntry:\n    from google.colab import userdata\n    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n    print(\"✅ API key loaded from Colab secrets\")\nexcept:\n    # Method 2: Manual input (fallback)\n    from getpass import getpass\n    print(\"💡 To use Colab secrets: Go to 🔑 (left sidebar) → Add new secret → Name: OPENAI_API_KEY\")\n    OPENAI_API_KEY = getpass(\"Enter your OpenAI API Key: \")\n\n# Set the API key as an environment variable\nimport os\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n\n# Validate that the API key is set\nif not OPENAI_API_KEY or OPENAI_API_KEY.strip() == \"\":\n    raise ValueError(\"❌ ERROR: No API key provided!\")\n\nprint(\"✅ Authentication configured!\")\n\n# Configure which OpenAI model to use\nOPENAI_MODEL = \"gpt-5-nano\"  # Cost-efficient model for function calling\nprint(f\"🤖 Selected Model: {OPENAI_MODEL}\")\n\n# Initialize OpenAI client\nfrom openai import OpenAI\nclient = OpenAI(api_key=OPENAI_API_KEY)\n\n# Configure LlamaIndex to use OpenAI\nfrom llama_index.core import Settings\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\nSettings.llm = None  # We'll use OpenAI client directly for more control\nSettings.embed_model = OpenAIEmbedding(api_key=OPENAI_API_KEY)\n\nprint(\"✅ OpenAI client configured for LlamaIndex!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7akcakenn9",
   "source": "# 🔗 Configure Neo4j connection\n\nNEO4J_URI = \"bolt://localhost:7687\"\nNEO4J_USER = \"neo4j\"\nNEO4J_PASSWORD = \"password123\"\n\n# Create Neo4j driver\ndriver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n\n# Test connection\ndef test_connection():\n    try:\n        with driver.session() as session:\n            result = session.run(\"MATCH (n) RETURN count(n) as count\")\n            count = result.single()[\"count\"]\n            print(\"✅ Successfully connected to Neo4j!\")\n            print(f\"📊 Current node count: {count}\")\n            return True\n    except Exception as e:\n        print(f\"❌ Connection failed: {e}\")\n        return False\n\ntest_connection()\n\n# Initialize LlamaIndex Neo4j graph store\n# Note: refresh_schema=False because APOC procedures are not installed in Neo4j Community Edition\ngraph_store = Neo4jGraphStore(\n    username=NEO4J_USER,\n    password=NEO4J_PASSWORD,\n    url=NEO4J_URI,\n    database=\"neo4j\",\n    refresh_schema=False,  # Disable APOC-dependent schema refresh\n)\n\nprint(\"\\n✅ Neo4j graph store initialized for LlamaIndex!\")\nprint(\"   (Schema refresh disabled - APOC not required)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "emh1fbvr1y6",
   "source": "# 🗄️ Initialize ChromaDB vector store\n\n# Create ChromaDB client (in-memory for Colab)\nchroma_client = chromadb.EphemeralClient()\n\n# Create a collection for our documents\ncollection_name = \"graphrag_documents\"\nchroma_collection = chroma_client.create_collection(name=collection_name)\n\n# Initialize LlamaIndex ChromaDB vector store\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n\nprint(\"✅ ChromaDB vector store initialized!\")\nprint(f\"   Collection: {collection_name}\")\nprint(f\"   Mode: Ephemeral (in-memory)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "jp16gyzza3",
   "source": "---\n## 📄 Part 3: Loading Sample Documents\n\n### Creating Unstructured Text Data\n\nIn this section, we'll create sample documents that simulate real-world scenarios:\n- **Project updates** describing team collaborations\n- **Research summaries** mentioning authors and citations\n- **Meeting notes** with action items and relationships\n\nThese documents contain **implicit entities** (people, projects, organizations) and **relationships** (works on, collaborates with, cites) that we'll extract using GPT-5-nano.\n\n### Why Unstructured Text?\n\nReal-world knowledge exists in:\n- Email threads and Slack messages\n- Research papers and technical reports\n- Meeting notes and project documentation\n- Customer support tickets\n- Legal contracts and medical records\n\n**GraphRAG automatically extracts structure** from this unstructured text, building a knowledge graph without manual data entry!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "31vru6c7fg3",
   "source": "# 📝 Create sample documents with rich entities and relationships\n\nsample_documents = [\n    {\n        \"title\": \"Q4 2024 AI Research Team Update\",\n        \"content\": \"\"\"\nThe AI Research team, led by Dr. Sarah Chen, has made significant progress on the \nCustomer Churn Prediction project. The team includes Marcus Johnson (Senior ML Engineer) \nand Priya Patel (Data Scientist), who have been collaborating closely with the \nData Engineering team headed by Tom Wilson.\n\nThe project leverages transformer-based models and achieved 89% accuracy in predicting \ncustomer churn. Sarah presented these results at the NeurIPS 2024 conference, where \nshe connected with Prof. Andrew Ng from Stanford University, who expressed interest \nin collaborating on future research.\n\nThe project is scheduled to move to production in Q1 2025, with support from the \nEngineering department led by David Kim. Marcus will be leading the deployment effort.\n\"\"\"\n    },\n    {\n        \"title\": \"Recommendation Engine v2 - Technical Design\",\n        \"content\": \"\"\"\nThe Recommendation Engine v2 project aims to improve our content recommendation system \nusing graph neural networks. The technical lead is Marcus Johnson, working with James Liu \n(ML Engineer) and Robert Brown (Senior Data Scientist).\n\nThis project builds upon research from \"Attention Is All You Need\" (Vaswani et al., 2017) \nand incorporates recent advances in graph representation learning. The team cited work by \nProf. Jure Leskovec from Stanford on knowledge graph embeddings as a key inspiration.\n\nJames Liu previously worked on the NLP Chatbot project with Priya Patel, bringing valuable \nexperience in transformer architectures. Robert Brown contributed his expertise in \nfeature engineering, drawing from his background at Google Research where he collaborated \nwith Dr. Geoffrey Hinton's team.\n\nThe project integrates with our existing Neo4j knowledge graph, which contains user behavior \ndata collected by the Analytics team under Sophie Martin (Product Manager).\n\"\"\"\n    },\n    {\n        \"title\": \"Fraud Detection System - Project Kickoff Notes\",\n        \"content\": \"\"\"\nMeeting Date: October 15, 2024\nAttendees: Marcus Johnson, Robert Brown, James Liu, Amy Zhang (Senior Backend Engineer), \nLisa Anderson (DevOps Engineer)\n\nThe Fraud Detection System project was initiated following a request from the Finance \ndepartment. This critical project will use anomaly detection algorithms to identify \nsuspicious transaction patterns in real-time.\n\nMarcus Johnson will serve as technical lead, with Robert Brown focusing on model development. \nThe system will be deployed on AWS infrastructure managed by Lisa Anderson. Amy Zhang will \nbuild the API layer for integration with our existing payment processing system.\n\nThe project references research on graph-based fraud detection by Prof. Danai Koutra from \nUniversity of Michigan. Robert Brown attended her keynote at KDD 2024 and proposed adapting \nher techniques for our use case.\n\nTimeline: 6-month project with go-live targeted for April 2025. The project will be reviewed \nmonthly by Alex Turner (CEO) and Jennifer Lee (CTO).\n\"\"\"\n    },\n    {\n        \"title\": \"Research Paper: Deep Learning for Time Series Forecasting\",\n        \"content\": \"\"\"\nAuthors: Priya Patel, Elena Rodriguez, Tom Wilson\nAffiliation: TechCorp AI Research Lab\n\nAbstract: This paper presents a novel approach to time series forecasting using deep learning \ntechniques. We build upon recent work by Prof. Yoshua Bengio on attention mechanisms and \npropose a hybrid model combining LSTMs with transformer architectures.\n\nOur approach was validated on the Customer Churn Prediction dataset, demonstrating significant \nimprovements over baseline methods. We acknowledge contributions from Dr. Sarah Chen, who \nprovided guidance on model architecture, and Marcus Johnson, who assisted with hyperparameter \ntuning.\n\nThis work was presented at the Real-time Analytics Dashboard internal symposium and received \npositive feedback from Jennifer Lee (CTO) and David Kim (VP of Engineering). We plan to submit \nthis work to ICML 2025.\n\nRelated Work: Our approach builds on \"BERT: Pre-training of Deep Bidirectional Transformers\" \n(Devlin et al., 2018) and \"Temporal Fusion Transformers\" (Lim et al., 2021). We also \nincorporate ideas from graph neural networks research by Prof. Jure Leskovec at Stanford.\n\"\"\"\n    },\n    {\n        \"title\": \"Engineering Team Quarterly Review - Q4 2024\",\n        \"content\": \"\"\"\nThe Engineering team, under VP David Kim, delivered exceptional results this quarter. \nKey accomplishments include:\n\n1. Infrastructure Migration: Led by Lisa Anderson and Mohammed Ali (Backend Engineer), \nthe team successfully migrated 80% of our services to Kubernetes. This project involved \nclose collaboration with the DevOps team and was completed ahead of schedule.\n\n2. Mobile App Redesign: Carlos Santos (Frontend Engineer) and Raj Sharma (Product Designer) \nshipped the new mobile interface, which increased user engagement by 35%. Nina Williams \n(UX Researcher) conducted extensive user testing that informed the final design.\n\n3. A/B Testing Platform: Sophie Martin (Product Manager) spearheaded the development of \nour new A/B testing infrastructure. Amy Zhang built the backend services, while Carlos \nSantos implemented the frontend dashboard.\n\nThe team collaborated extensively with the Data Science department (Dr. Sarah Chen) on the \nReal-time Analytics Dashboard project. Tom Wilson (Data Engineer) built the data pipelines, \nwhile Amy Zhang and Elena Rodriguez (Data Analyst) created the visualization layer.\n\nNext quarter priorities were set in consultation with Alex Turner (CEO) and Jennifer Lee (CTO). \nThe focus will be on AI/ML model deployment automation and expanding our cloud infrastructure.\n\"\"\"\n    },\n    {\n        \"title\": \"Partnership Announcement: TechCorp and Stanford AI Lab\",\n        \"content\": \"\"\"\nTechCorp is excited to announce a research partnership with Stanford University's AI Lab, \nled by Prof. Andrew Ng and Prof. Jure Leskovec. This collaboration emerged from discussions \nat NeurIPS 2024 where Dr. Sarah Chen presented our work on customer churn prediction.\n\nThe partnership will focus on three areas:\n\n1. Graph Neural Networks: Prof. Jure Leskovec will advise our team (Marcus Johnson, \nRobert Brown, James Liu) on applying graph neural networks to recommendation systems.\n\n2. Transfer Learning: Prof. Andrew Ng will collaborate with Priya Patel and Maria Garcia \n(Junior ML Engineer) on transfer learning techniques for computer vision applications \nrelated to our Computer Vision API project.\n\n3. Knowledge Graphs: The Stanford team will work with our Data Engineering group (Tom Wilson, \nElena Rodriguez) to enhance our Neo4j-based knowledge graph infrastructure.\n\nThis partnership was championed by Jennifer Lee (CTO) and Alex Turner (CEO), with support \nfrom David Kim (VP of Engineering) and Dr. Sarah Chen (VP of Data Science). The first joint \nresearch workshop is scheduled for January 2025 at Stanford's campus.\n\nProf. Andrew Ng commented: \"TechCorp's work on combining graph databases with machine learning \naligns perfectly with our research vision. We're particularly impressed by the team's implementation \nof attention mechanisms in their recommendation engine.\"\n\"\"\"\n    }\n]\n\n# Convert to LlamaIndex Document objects\ndocuments = [\n    Document(\n        text=doc[\"content\"],\n        metadata={\"title\": doc[\"title\"]}\n    )\n    for doc in sample_documents\n]\n\nprint(f\"✅ Created {len(documents)} sample documents\")\nprint(\"\\n📄 Document titles:\")\nfor i, doc in enumerate(sample_documents, 1):\n    print(f\"  {i}. {doc['title']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "003icyb33rt7s",
   "source": "---\n## 🤖 Part 4: LLM-Powered Entity Extraction\n\n### Automating Knowledge Graph Construction\n\nInstead of manually identifying entities and relationships (as in Notebook 1), we'll use **GPT-5-nano** to automatically extract:\n\n- **Entities**: People, organizations, projects, technologies, locations\n- **Relationships**: works_on, collaborates_with, leads, cites, presents_at\n- **Properties**: Roles, affiliations, dates, locations\n\n### How It Works\n\n1. **Prompt Engineering**: We'll craft prompts that instruct the LLM to extract structured information\n2. **Entity Recognition**: GPT-5-nano identifies named entities in the text\n3. **Relationship Extraction**: The LLM infers connections between entities\n4. **Structured Output**: We'll parse the LLM response into graph-ready format\n\nThis approach scales to thousands of documents without manual annotation!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3w319j5nw59",
   "source": "# 🤖 Create entity extraction function using GPT-5-nano\n\ndef extract_entities_and_relationships(text: str, doc_title: str = \"\") -> Dict[str, Any]:\n    \"\"\"\n    Use GPT-5-nano to extract entities and relationships from text.\n    \n    Args:\n        text: The document text to analyze\n        doc_title: Optional document title for context\n        \n    Returns:\n        Dictionary containing extracted entities and relationships\n    \"\"\"\n    \n    extraction_prompt = f\"\"\"\nExtract entities and relationships from the following text. Return the results as a JSON object.\n\nTEXT:\n{text[:2000]}  # Limit to first 2000 chars for efficiency\n\nExtract:\n1. **Entities** with types: Person, Organization, Project, Technology, Location, Event, Concept\n2. **Relationships** between entities (who works with whom, who leads what, etc.)\n\nReturn JSON format:\n{{\n  \"entities\": [\n    {{\"name\": \"Entity Name\", \"type\": \"Person|Organization|Project|Technology|Location|Event|Concept\", \"properties\": {{\"role\": \"...\", \"affiliation\": \"...\"}}}},\n    ...\n  ],\n  \"relationships\": [\n    {{\"source\": \"Entity 1\", \"target\": \"Entity 2\", \"type\": \"works_on|collaborates_with|leads|cites|presents_at|employed_by\", \"properties\": {{}}}},\n    ...\n  ]\n}}\n\nFocus on the most important entities and clear relationships. Be concise.\n\"\"\"\n    \n    try:\n        # Call GPT-5-nano using the Responses API\n        response = client.responses.create(\n            model=\"gpt-5-nano\",\n            input=extraction_prompt,\n            reasoning={\"effort\": \"minimal\"}  # Optimize for speed\n        )\n        \n        # Extract the response text\n        result_text = response.output_text if hasattr(response, 'output_text') else str(response)\n        \n        # Parse JSON (handle cases where LLM might add markdown formatting)\n        if \"```json\" in result_text:\n            result_text = result_text.split(\"```json\")[1].split(\"```\")[0]\n        elif \"```\" in result_text:\n            result_text = result_text.split(\"```\")[1].split(\"```\")[0]\n        \n        extracted = json.loads(result_text.strip())\n        extracted[\"document_title\"] = doc_title\n        \n        return extracted\n        \n    except Exception as e:\n        print(f\"❌ Extraction error: {e}\")\n        return {\"entities\": [], \"relationships\": [], \"document_title\": doc_title}\n\nprint(\"✅ Entity extraction function created!\")\nprint(\"   Model: gpt-5-nano\")\nprint(\"   Format: JSON output with entities and relationships\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gh25yyb239h",
   "source": "# 🔄 Extract entities from all documents\n\nprint(\"🤖 Extracting entities and relationships from documents...\")\nprint(\"This will take 30-60 seconds (using GPT-5-nano)...\\n\")\n\nextracted_data = []\n\nfor i, doc in enumerate(sample_documents, 1):\n    print(f\"📄 Processing document {i}/{len(sample_documents)}: {doc['title'][:50]}...\")\n    \n    result = extract_entities_and_relationships(doc[\"content\"], doc[\"title\"])\n    extracted_data.append(result)\n    \n    # Show sample of extracted entities\n    if result[\"entities\"]:\n        print(f\"   ✓ Found {len(result['entities'])} entities, {len(result['relationships'])} relationships\")\n    else:\n        print(f\"   ⚠️ No entities extracted\")\n    \nprint(f\"\\n✅ Extraction complete!\")\nprint(f\"📊 Total entities extracted: {sum(len(d['entities']) for d in extracted_data)}\")\nprint(f\"🔗 Total relationships extracted: {sum(len(d['relationships']) for d in extracted_data)}\")\n\n# Show a sample of extracted data\nprint(\"\\n📋 Sample extraction from first document:\")\nif extracted_data[0][\"entities\"]:\n    print(f\"\\\\nEntities (first 3):\")\n    for entity in extracted_data[0][\"entities\"][:3]:\n        print(f\"  - {entity['name']} ({entity['type']})\")\n    \n    print(f\"\\\\nRelationships (first 3):\")\n    for rel in extracted_data[0][\"relationships\"][:3]:\n        print(f\"  - {rel['source']} --[{rel['type']}]--> {rel['target']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kikp3k7yle",
   "source": "---\n## 🏗️ Part 5: Building the Knowledge Graph Automatically\n\n### From Extracted Data to Neo4j\n\nNow that we've extracted entities and relationships using GPT-5-nano, we'll automatically populate our Neo4j knowledge graph. This process:\n\n1. **Deduplicates entities** (merge multiple mentions of \"Sarah Chen\" into one node)\n2. **Creates nodes** for each unique entity\n3. **Establishes relationships** between entities\n4. **Adds properties** (roles, affiliations, etc.)\n5. **Links documents** to entities they mention\n\nThis is where **manual work** (Notebook 1) becomes **fully automated** (Notebook 2)!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🏗️ Build the knowledge graph from extracted data\n\n# Clear existing data\nwith driver.session() as session:\n    session.run(\"MATCH (n) DETACH DELETE n\")\n    print(\"🧹 Cleared existing graph data\\n\")\n\n# Helper function to insert entities and relationships\ndef build_graph_from_extractions(extracted_data_list):\n    \"\"\"\n    Build Neo4j knowledge graph from LLM-extracted data.\n    \"\"\"\n    with driver.session() as session:\n        total_entities = 0\n        total_relationships = 0\n        \n        for extraction in extracted_data_list:\n            doc_title = extraction.get(\"document_title\", \"Unknown\")\n            \n            # Create Document node\n            session.run(\n                \"\"\"\n                MERGE (d:Document {title: $title})\n                \"\"\",\n                title=doc_title\n            )\n            \n            # Create entity nodes\n            for entity in extraction.get(\"entities\", []):\n                name = entity.get(\"name\", \"\").strip()\n                entity_type = entity.get(\"type\", \"Entity\")\n                properties = entity.get(\"properties\", {})\n                \n                if not name:\n                    continue\n                \n                # Create or merge entity node\n                query = f\"\"\"\n                MERGE (e:{entity_type} {{name: $name}})\n                SET e += $properties\n                \"\"\"\n                session.run(query, name=name, properties=properties)\n                \n                # Link entity to document\n                session.run(\n                    \"\"\"\n                    MATCH (e {{name: $name}}), (d:Document {title: $doc_title})\n                    MERGE (e)-[:MENTIONED_IN]->(d)\n                    \"\"\",\n                    name=name,\n                    doc_title=doc_title\n                )\n                \n                total_entities += 1\n            \n            # Create relationships\n            for rel in extraction.get(\"relationships\", []):\n                source = rel.get(\"source\", \"\").strip()\n                target = rel.get(\"target\", \"\").strip()\n                rel_type = rel.get(\"type\", \"RELATED_TO\").upper().replace(\" \", \"_\")\n                rel_props = rel.get(\"properties\", {})\n                \n                if not source or not target:\n                    continue\n                \n                session.run(\n                    f\"\"\"\n                    MATCH (s {{name: $source}}), (t {{name: $target}})\n                    MERGE (s)-[r:{rel_type}]->(t)\n                    SET r += $properties\n                    \"\"\",\n                    source=source,\n                    target=target,\n                    properties=rel_props\n                )\n                \n                total_relationships += 1\n        \n        return total_entities, total_relationships\n\n# Build the graph\nprint(\"🏗️ Building knowledge graph in Neo4j...\")\nentities_created, rels_created = build_graph_from_extractions(extracted_data)\n\nprint(f\"\\n✅ Knowledge graph built successfully!\")\nprint(f\"   📊 Entities created: {entities_created}\")\nprint(f\"   🔗 Relationships created: {rels_created}\")\n\n# Verify the graph\nwith driver.session() as session:\n    result = session.run(\"\"\"\n        MATCH (n)\n        RETURN labels(n)[0] as type, count(*) as count\n        ORDER BY count DESC\n    \"\"\")\n    print(f\"\\n📋 Node types in graph:\")\n    for record in result:\n        print(f\"   - {record['type']}: {record['count']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 🎯 Part 6: Creating Vector Embeddings\n\n### Why Vector Embeddings?\n\nWhile our knowledge graph captures **structure** (who knows whom, who works on what), vector embeddings capture **semantic meaning**. By combining both, we get:\n\n- **Semantic search**: Find conceptually similar content\n- **Entity disambiguation**: Distinguish between entities with similar names using context\n- **Hybrid retrieval**: Use vector similarity to find entry points, then traverse the graph\n\n### What We'll Create\n\n- Document embeddings for each text\n- Entity embeddings (using entity names + context)\n- Store everything in ChromaDB for fast similarity search"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🎯 Create vector embeddings for documents\n\n# Split documents into chunks for better retrieval\nfrom llama_index.core.node_parser import SentenceSplitter\n\nsplitter = SentenceSplitter(chunk_size=512, chunk_overlap=50)\nnodes = splitter.get_nodes_from_documents(documents)\n\nprint(f\"📄 Split {len(documents)} documents into {len(nodes)} chunks\")\n\n# Create embeddings and store in ChromaDB\nfrom llama_index.core import VectorStoreIndex, StorageContext\n\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\nprint(\"\\n🔄 Creating embeddings (this may take 30-60 seconds)...\")\nvector_index = VectorStoreIndex(\n    nodes,\n    storage_context=storage_context,\n    show_progress=True\n)\n\nprint(\"\\n✅ Vector embeddings created and stored in ChromaDB!\")\nprint(f\"   📊 Total document chunks embedded: {len(nodes)}\")\nprint(f\"   🎯 Embedding model: text-embedding-ada-002\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 🔍 Part 7-8: Vector Search vs Graph Search\n\n### Traditional RAG (Vector-Only)\n\nTraditional RAG uses only vector similarity:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🔍 Traditional Vector-Only Search (Baseline)\n\ndef vector_search(query: str, top_k: int = 3):\n    \"\"\"\n    Pure vector similarity search (traditional RAG baseline).\n    \"\"\"\n    query_engine = vector_index.as_query_engine(similarity_top_k=top_k)\n    response = query_engine.query(query)\n    \n    return response\n\n# Test vector search\nquery = \"Who is working on the Recommendation Engine project?\"\nprint(f\"❓ Query: {query}\\n\")\nprint(\"📊 Vector Search Results:\")\nresult = vector_search(query)\nprint(f\"\\nAnswer: {result}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Graph-Based Retrieval\n\nGraph search uses Cypher to traverse relationships:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🔗 Graph-Based Search\n\ndef graph_search(entity_name: str):\n    \"\"\"\n    Retrieve entity and its connections from the knowledge graph.\n    \"\"\"\n    with driver.session() as session:\n        result = session.run(\n            \"\"\"\n            MATCH (e {name: $name})-[r]-(connected)\n            RETURN e.name as entity, type(r) as relationship, \n                   connected.name as connected_entity, labels(connected)[0] as type\n            LIMIT 20\n            \"\"\",\n            name=entity_name\n        )\n        return [dict(record) for record in result]\n\n# Test graph search\nprint(\"🔗 Graph Search Results for 'Marcus Johnson':\\n\")\nconnections = graph_search(\"Marcus Johnson\")\nfor conn in connections[:5]:\n    print(f\"  {conn['entity']} --[{conn['relationship']}]--> {conn['connected_entity']} ({conn['type']})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 🚀 Part 9-10: Hybrid Search - GraphRAG in Action\n\n### Combining Vector + Graph\n\nGraphRAG combines both approaches:\n1. Use vector search to find relevant entities\n2. Traverse the graph to find connected context\n3. Assemble rich, relationship-aware context for the LLM"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🚀 GraphRAG: Hybrid Vector + Graph Search\n\ndef graphrag_search(query: str, top_k: int = 3, max_hops: int = 2):\n    \"\"\"\n    Hybrid search combining vector similarity and graph traversal.\n    \n    Steps:\n    1. Vector search to find relevant documents\n    2. Extract mentioned entities from those documents\n    3. Graph traversal to find connected entities and documents\n    4. Assemble comprehensive context\n    \"\"\"\n    print(f\"🔍 GraphRAG Search for: '{query}'\\n\")\n    \n    # Step 1: Vector search for relevant documents\n    print(\"📊 Step 1: Vector search for relevant documents...\")\n    vector_results = vector_index.as_query_engine(similarity_top_k=top_k).query(query)\n    \n    # Step 2: Extract entities mentioned in top documents\n    print(\"📋 Step 2: Identifying entities from results...\")\n    entities_found = set()\n    \n    # Find entities connected to retrieved documents\n    with driver.session() as session:\n        result = session.run(\n            \"\"\"\n            MATCH (e)-[:MENTIONED_IN]->(d:Document)\n            RETURN DISTINCT e.name as entity, labels(e)[0] as type\n            LIMIT 10\n            \"\"\"\n        )\n        for record in result:\n            entities_found.add(record[\"entity\"])\n    \n    print(f\"   Found {len(entities_found)} entities\")\n    \n    # Step 3: Graph traversal from these entities\n    print(\"🔗 Step 3: Traversing knowledge graph...\")\n    graph_context = []\n    \n    for entity in list(entities_found)[:5]:  # Limit for demo\n        connections = graph_search(entity)\n        graph_context.extend(connections[:3])\n    \n    print(f\"   Retrieved {len(graph_context)} relationship triples\")\n    \n    # Step 4: Assemble final context\n    print(\"\\n✅ GraphRAG Results:\\n\")\n    print(f\"📊 Vector-based answer:\\n{vector_results}\\n\")\n    print(f\"🔗 Graph-enriched context:\")\n    for ctx in graph_context[:5]:\n        print(f\"   - {ctx['entity']} --[{ctx['relationship']}]--> {ctx['connected_entity']}\")\n    \n    return {\"vector_answer\": str(vector_results), \"graph_context\": graph_context}\n\n# Test GraphRAG\nresult = graphrag_search(\"Who collaborates with Marcus Johnson on AI projects?\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 🎓 Part 11: Advanced GraphRAG Patterns\n\n### Multi-Hop Reasoning\n\nGraphRAG excels at multi-hop questions that require traversing multiple relationships:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🎓 Advanced Pattern: Multi-Hop Reasoning\n\ndef multi_hop_query(start_entity: str, relationship_pattern: str, hops: int = 2):\n    \"\"\"\n    Traverse multiple relationship hops in the knowledge graph.\n    Example: Find people who work with people who collaborated with start_entity\n    \"\"\"\n    with driver.session() as session:\n        query = f\"\"\"\n        MATCH path = (start {{name: $start}})-[*1..{hops}]-(connected)\n        WHERE connected:Person OR connected:Organization\n        RETURN DISTINCT connected.name as name, \n               labels(connected)[0] as type,\n               length(path) as distance\n        ORDER BY distance\n        LIMIT 15\n        \"\"\"\n        result = session.run(query, start=start_entity)\n        return [dict(record) for record in result]\n\n# Example: Find people within 2 degrees of Sarah Chen\nprint(\"🔗 Multi-hop query: People within 2 connections of Sarah Chen\\n\")\nresults = multi_hop_query(\"Sarah Chen\", \"COLLABORATES_WITH|WORKS_ON\", hops=2)\n\nfor r in results[:10]:\n    print(f\"  {r['name']} ({r['type']}) - {r['distance']} hop(s) away\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Entity Disambiguation\n\nGraphRAG uses graph context to disambiguate entities:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🎯 Entity Disambiguation using Graph Context\n\ndef disambiguate_entity(entity_name: str):\n    \"\"\"\n    Use graph relationships to provide context for entity disambiguation.\n    \"\"\"\n    with driver.session() as session:\n        result = session.run(\n            \"\"\"\n            MATCH (e {name: $name})\n            OPTIONAL MATCH (e)-[r1]-(connected1)\n            OPTIONAL MATCH (e)-[:MENTIONED_IN]->(d:Document)\n            RETURN e.name as name, \n                   labels(e)[0] as type,\n                   collect(DISTINCT type(r1)) as relationship_types,\n                   collect(DISTINCT connected1.name)[0..5] as connected_to,\n                   collect(DISTINCT d.title)[0..3] as mentioned_in_docs\n            \"\"\"\n            ,\n            name=entity_name\n        )\n        \n        for record in result:\n            print(f\"Entity: {record['name']} ({record['type']})\")\n            print(f\"  Connected via: {', '.join(record['relationship_types'][:5])}\")\n            print(f\"  Connected to: {', '.join([c for c in record['connected_to'] if c][:5])}\")\n            print(f\"  Mentioned in: {', '.join(record['mentioned_in_docs'])}\")\n\n# Example\nprint(\"🔍 Disambiguating 'Marcus Johnson':\\n\")\ndisambiguate_entity(\"Marcus Johnson\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 🚀 Part 12: Next Steps & Production Considerations\n\n### Congratulations! 🎉\n\nYou've learned how to build complete GraphRAG systems that combine:\n- ✅ LLM-powered entity extraction (GPT-5-nano)\n- ✅ Automated knowledge graph construction (Neo4j)\n- ✅ Vector embeddings for semantic search (ChromaDB)\n- ✅ Hybrid retrieval combining graphs and vectors\n- ✅ Multi-hop reasoning and entity disambiguation\n\n### 🏭 Production Considerations\n\n**Scaling Entity Extraction:**\n- Batch processing for large document corpora\n- Caching LLM extractions to reduce API costs\n- Fine-tuning models for domain-specific entity types\n- Using cheaper models (gpt-5-nano) for extraction, premium models for generation\n\n**Knowledge Graph Optimization:**\n- Entity resolution and deduplication\n- Confidence scores for extracted relationships\n- Temporal relationships (when did X work with Y?)\n- Graph embeddings for entity similarity\n\n**Vector Store Scaling:**\n- Persistent ChromaDB or Pinecone for production\n- Hybrid search with BM25 + dense embeddings\n- Metadata filtering for faster retrieval\n- Query result caching\n\n**GraphRAG Query Optimization:**\n- Limit graph traversal depth to prevent slowdowns\n- Use Cypher query optimization (indexes, profiling)\n- Parallel retrieval (vector + graph searches simultaneously)\n- LLM result caching for common queries\n\n### 📚 Further Learning\n\n1. **LlamaIndex Graph RAG Documentation**: Advanced GraphRAG patterns\n2. **Neo4j Graph Data Science**: Centrality, community detection, graph algorithms\n3. **Hybrid Search Research**: Papers on combining dense + sparse + graph retrieval\n4. **Entity Linking**: Linking extracted entities to knowledge bases (Wikidata, DBpedia)\n\n### 🛠️ Practice Exercises\n\n1. **Add New Documents**: Extract entities from your own documents\n2. **Custom Entity Types**: Modify extraction prompts for your domain\n3. **Complex Queries**: Write multi-hop Cypher queries for your use case\n4. **Evaluation**: Compare GraphRAG vs traditional RAG on complex questions\n5. **Visualization**: Use NetworkX to visualize the extracted knowledge graph\n\n### 🎯 Key Takeaways\n\n- **GraphRAG > Traditional RAG** for entity-centric and relationship-heavy domains\n- **LLMs automate** what used to require manual knowledge engineering\n- **Hybrid search** provides both semantic and structural relevance\n- **Knowledge graphs** enable explainable, multi-hop reasoning\n- **Production systems** require careful optimization of extraction, storage, and retrieval\n\nYou now have the skills to build production GraphRAG systems! 🚀\n\n### 📊 System Architecture Summary\n\n```\nDocuments (Unstructured Text)\n      |\n      v\nGPT-5-nano (Entity Extraction)\n      |\n      v\nEntities + Relationships (Structured)\n      |\n      ├─────> Neo4j (Knowledge Graph)\n      |\n      └─────> ChromaDB (Vector Embeddings)\n             |\n             v\n        GraphRAG Engine\n             |\n             ├─> Vector Search (Semantic)\n             ├─> Graph Traversal (Structural)\n             └─> Hybrid Results (Best of Both)\n```\n\nThank you for completing this notebook! See you in your next AI project! 🎓"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "execution_count": null,
   "source": "# 🧹 Cleanup: Close connections\n\nprint(\"🧹 Closing database connections...\")\ndriver.close()\nprint(\"✅ Connections closed!\")\nprint(\"\\n👋 Thanks for learning GraphRAG!\")\nprint(\"🚀 Now go build amazing knowledge-graph-powered AI applications!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}